---
title: "Scholarship Data Exploration"
author: "Paul Hively"
date: "August 4, 2016"
output: html_document
---

Source available [here](https://github.com/phively/gsb-scholarship/blob/master/1%20data%20exploration.Rmd).

The goal of this project is to identify covariates and factors associated with scholarship funds. A predictive model would be nice, but for now my main focus is explanation.

Load the libraries and data and do some cleanup.

```{r, message=F, warning=F, cache=F}
source("LIBRARIES.R")
dat <- read.csv("data\\2016-08-09 ABEM FY17.csv", header=T, stringsAsFactors=F)

## Data cleanup
mdat <- dat %>%
  # Select desired columns
  select(student.gifts = Giving.Student.Support,
         id = Entity.ID,
         deg.year = Booth.ClassYr.or.RecYr,
         deg.prg = Booth.Program.Group,
         employ.yrs = Employ.Years.At.Current.Company,
         nice.title = Bus.Title.High.Lvl,
         gift.cap = Gift.Capacity.Numerical.Amt..CR.,
         fys.giving = Giving.FYs.of.Giving,
         fys.recent = Giving.FY.in.Last.5,
         first.gift = Giving.First.Trans.Amt,
         af.gifts = Giving.Booth.AF.Gifts,
         lt.giving = Booth.Lifetime.Giving,
         spouse = Spouse.Married.UC.Booth,
         known.to = Rel.Known.Tos.Count,
         stewardee = Alloc.Stewardee.Student.Support,
         committees = Committee.in.Last.3.FY,
         vols = Vol.Acts..BUS.,
         speak = Events.Vol.Speaker,
         stu.acts = Student.Acts..BUS.,
         lead.facil = Student.Acts.LEAD.Facilitator,
         stu.supp = Vol.Act.Student.Supporter,
         scholarship = Scholarships.Count,
         events = Events.Attended..BUS.,
         events.stu = Events.Attended..BUS..Student,
         nonprofit = Nonprofit.Leadership.Flag) %>%
  # Drop null rows
  filter(!is.na(id)) %>%
  # Convert string columns to factor
  mutate(deg.prg = as.factor(deg.prg) %>% relevel("Full-Time"),
         spouse = as.factor(spouse)) %>%
  # Convert currency columns to numeric
  CurrencyToNumeric(fields = c("student.gifts", "gift.cap", "first.gift", "lt.giving")) %>%
  # Exclude non-alumni
  filter(deg.prg != '')
# Replace NAs with 0
mdat[is.na(mdat)] <- 0

# View random sample of resulting data
set.seed(123)
rand <- sample(1:nrow(mdat), nrow(mdat))
mdat %>% select(-id) %>% slice(rand) %>% str()
```

Here, `student.gifts` (dollars given to student support) is the outcome variable being measured. I've (semi-arbitrarily) chosen a few variables to examine based on my own judgement and suggestions from the rest of the team. Begin by looking for plausible transformations.

```{r, echo=F, message=F, warning=F, cache=F}
## Drop $0 donors
ggdat <- mdat %>% filter(student.gifts > 0)
# Base, and 3 basic transformations
ggplot(ggdat, aes(x=student.gifts)) + geom_histogram(alpha=.5, binwidth=50000) + labs(title="Student support giving, untransformed") + scale_x_continuous(labels=scales::dollar)
ggplot(ggdat, aes(x=student.gifts)) + geom_histogram(alpha=.5, binwidth=100) + labs(title="Student support giving, square root transformation") + scale_x_sqrt(labels=scales::dollar)
ggplot(ggdat, aes(x=student.gifts)) + geom_histogram(alpha=.5, binwidth=.25) + labs(title=expression(paste("Student support giving, ", log[10], " transformation"))) + scale_x_log10(labels=scales::dollar, breaks=10^(0:7), minor_breaks=NULL)
# Log 10 transformation is the best
```

As usual, the $\text{log}_{10}$ transformation looks good. It does require dropping non-donors; one thought is to fit an explanatory model only to (a random sample of) those people who have made gifts and make predictions for the rest of the population. Of course, there's no particular reason to think donors and non-donors are comparable, but it's a starting point.

```{r, message=F, warning=F, cache=F}
mdat <- mdat %>% mutate(student.gifts.lt = log(student.gifts, base=10), lt.giving.lt = log(lt.giving, base=10))
ggdat <- mdat %>% filter(student.gifts > 0)
```

# Exploration

Exploring the factors and covariates. All plots exclude non-donors:

```{r, echo=F, message=F, warning=F, cache=F}
# Tabulation of spouses
mdat %>% mutate(count = 1) %>% group_by(spouse) %>% summarise(count = sum(count), mean.giving = mean(student.gifts)) %>% kable(digits=2)
mdat %>% filter(student.gifts > 0) %>% mutate(count = 1) %>% group_by(spouse) %>% summarise(donor.count = sum(count), mean.donor.giving = mean(student.gifts)) %>% kable(digits=2)

# Histogram of transformed giving by spouses
ggplot(ggdat, aes(x=student.gifts, y=..density..)) + geom_density() + geom_histogram(alpha=.5, binwidth=.25) + labs(title=expression(paste("Student support giving, ", log[10], " transformation"))) + scale_x_log10(labels=scales::dollar, breaks=10^(0:7), minor_breaks=NULL) + facet_grid(spouse ~ .)

# Boxplot of giving by spouses
ggplot(ggdat, aes(x=spouse, y=student.gifts)) + geom_boxplot(alpha=.5) + scale_y_log10(labels=scales::dollar, breaks=10^(0:7), minor_breaks=NULL)
```

Ignoring other covariates, married donors are more generous than unmarried ones. On to the numerical variables.

```{r, echo=F, message=F, warning=F, cache=F}
# Axis formatting
gg.y.logdollar <- list(scale_y_log10(labels=scales::dollar, breaks=10^(0:7), minor_breaks=NULL, limits=c(10^0, 10^7)))
gg.x.logdollar <- list(scale_x_log10(labels=scales::dollar, breaks=10^(0:7), minor_breaks=NULL, limits=c(10^0, 10^7)))
gg.fitline <- list(stat_smooth(method=lm, alpha=.25))

# Degree year
ggplot(ggdat, aes(x=deg.year, y=student.gifts)) + geom_point() + gg.y.logdollar + gg.fitline
# Degree program
ggplot(ggdat, aes(x=deg.prg, y=student.gifts)) + geom_boxplot(alpha=.5) + gg.y.logdollar
```

Younger alumni have given less, which follows given their lower lifetime earnings. Part-time alumni appear to be less generous than the rest.

```{r, echo=F, message=F, warning=F, cache=F}
# Length of employment
ggplot(ggdat, aes(x=employ.yrs, y=student.gifts)) + geom_point() + gg.y.logdollar + gg.fitline
# Nice title (high-level)
ggplot(ggdat, aes(x=factor(nice.title), y=student.gifts)) + geom_boxplot(alpha=.5) + gg.y.logdollar
```

Being employed longer and having a fancy job title is associated with increased giving to student causes, ignoring other covariates. (I'm going to stop writing that but it's assumed for the rest.)

```{r, echo=F, message=F, warning=F, cache=F}
# Gift capacity
ggplot(ggdat, aes(x=gift.cap, y=student.gifts)) + geom_point(alpha=.5) + gg.x.logdollar + gg.y.logdollar + gg.fitline
# Total FYs of giving
ggplot(ggdat, aes(x=fys.giving, y=student.gifts)) + geom_point(alpha=.5) + gg.y.logdollar + gg.fitline
# Recent FYs (last 5) of giving
ggplot(ggdat, aes(x=fys.recent, y=student.gifts)) + geom_point() + gg.y.logdollar + gg.fitline
# First gift amount
ggplot(ggdat, aes(x=first.gift, y=student.gifts)) + geom_point() + gg.y.logdollar + gg.x.logdollar + gg.fitline
# Lifetime giving
ggplot(ggdat, aes(x=lt.giving, y=student.gifts)) + geom_point() + gg.y.logdollar + gg.x.logdollar + gg.fitline
# Years of AF giving
ggplot(ggdat, aes(x=af.gifts, y=student.gifts)) + geom_point() + gg.y.logdollar + gg.fitline
```

Previous giving and gift capacity are strongly associated with other giving behaviors, as has been repeatedly found in the past. In particular, note the correlation between first gift and student giving amounts -- there are a few interesting patterns apaprent, such as the cluster of points around $x=y$ and shrinking variances as first gift amounts increase.

```{r, echo=F, message=F, warning=F, cache=F}
# Known to count
ggplot(ggdat, aes(x=known.to, y=student.gifts)) + geom_point() + gg.y.logdollar + gg.fitline + scale_x_sqrt() + labs(x="known.to (sqrt scale)")
# Number of student allocations as a stewardee
ggplot(ggdat, aes(x=stewardee, y=student.gifts)) + geom_point() + gg.y.logdollar + gg.fitline
# Number of committees
ggplot(ggdat, aes(x=committees, y=student.gifts)) + geom_point() + gg.y.logdollar + gg.fitline
# Number of volunteer activities
ggplot(ggdat, aes(x=vols, y=student.gifts)) + geom_point() + gg.y.logdollar + gg.fitline
# Number of speaking engagements
ggplot(ggdat, aes(x=speak, y=student.gifts)) + geom_point() + gg.y.logdollar + gg.fitline
# Number of student activities
ggplot(ggdat, aes(x=stu.acts, y=student.gifts)) + geom_point() + gg.y.logdollar + gg.fitline
# Lead Facilitator indicator
ggplot(ggdat, aes(x=as.factor(lead.facil), y=student.gifts)) + geom_boxplot(alpha=.5) + gg.y.logdollar
# Student supporter indicator
ggplot(ggdat, aes(x=as.factor(stu.supp), y=student.gifts)) + geom_boxplot(alpha=.5) + gg.y.logdollar
# Booth events attended
ggplot(ggdat, aes(x=events, y=student.gifts)) + geom_point() + gg.y.logdollar + gg.fitline
# Booth student events attended
ggplot(ggdat, aes(x=events.stu, y=student.gifts)) + geom_point() + gg.y.logdollar + gg.fitline
# Nonprofit board membership
ggplot(ggdat, aes(x=as.factor(nonprofit), y=student.gifts)) + geom_boxplot(alpha=.5) + gg.y.logdollar
```

A bit of a mixed bag here: people who are involved as *students* are not more likely to be donors, but those who are involved as alumni are. In particular, note the difference between student and alumni event attendance. Many of these are counts and should be transformed (sqrt) if used in a lm or glm.

```{r, echo=F, message=F, warning=F, cache=F}
# Number of scholarships
ggplot(ggdat, aes(x=scholarship, y=student.gifts)) + geom_point() + gg.y.logdollar + gg.fitline
```

And here's the big surprise: no association, or even slightly negative, between receiving scholarships and giving to student causes. I expect that receiving scholarships is associated with age, for example, so there might still be a story there.

# Variable importance

Random forests (Breiman) are an established ensemble method for classification and regression. We can see which (untransformed) variables are selected by the model as a proxy for variable importance.

```{r, echo=F, message=F, warning=F, cache=T}
# Remove unused variables
rf.dat <- ggdat %>% select(-id, -student.gifts)
# Variable importance (tree method)
set.seed(5640303)
rf <- randomForest(student.gifts.lt ~ ., data=rf.dat, importance=T)
```
```{r, echo=F, message=F, warning=F, cache=F}
# Extract importances
rf.imp <- data.frame(importance(rf, scale=F))
# ggplot theme
gg.rf.theme <- list(theme(axis.text.x=element_text(angle=90, hjust=1), panel.grid.minor=element_line(linetype="dotted")), labs(title="Variable importances", x="Variable", y="Increase in MSE"))
# Plot importances
ggplot(rf.imp, aes(x=reorder(rownames(rf.imp), X.IncMSE), y=X.IncMSE)) + geom_bar(stat="identity", alpha=.5) + scale_y_continuous(minor_breaks=seq(0, .5, .02)) + gg.rf.theme
```

This measure of variable importance gives the percent change in MSE after removing the variable. Unsurprisingly, being a current stewardee of a scholarship fund is the best predictor, followed by first gift size and gift capacity. Try again without these three indicators:

```{r, echo=F, message=F, warning=F, cache=T}
# Remove unused variables
rf.dat <- ggdat %>% select(-id, -student.gifts, -stewardee, -gift.cap, -first.gift)
# Variable importance (tree method)
set.seed(7343507)
rf <- randomForest(student.gifts.lt ~ ., data=rf.dat, importance=T)
# Extract importances
rf.imp <- data.frame(importance(rf, scale=F))
ggplot(rf.imp, aes(x=reorder(rownames(rf.imp), X.IncMSE), y=X.IncMSE)) + geom_bar(stat="identity", alpha=.5) + scale_y_continuous(minor_breaks=seq(0, .2, .01)) + gg.rf.theme
```

Now the engagement indicators really pop. For modeling, `stewardee` and `gift.cap` should certainly be dropped, and `first.gift` is borderline, as it's perfectly correlated with the response variable `student.gifts` in a subset of cases as seen during exploration above.

# Basic linear model

Begin with a basic lm with transformed variables.

```{r, message=F, warning=F, cache=F}
# Remove unused variables
lmdat <- 
  mdat %>% filter(student.gifts > 0) %>% select(-student.gifts, -stewardee, -gift.cap, -first.gift)
# Recenter deg.year
lmdat$deg.year.ctr <- lmdat$deg.year - min(lmdat$deg.year)
# Linear model for donors
lmod <- lm(
  student.gifts.lt ~
    # Low importance
     spouse + sqrt(events.stu) + lead.facil + nice.title + sqrt(scholarship) + stu.supp +
    # Use as-is
    deg.year.ctr + deg.prg + nice.title + fys.recent + nonprofit +
    # Sqrt transform
    sqrt(employ.yrs) + sqrt(fys.giving) + sqrt(af.gifts) + sqrt(known.to) + sqrt(committees) +
    sqrt(vols) + sqrt(speak) + sqrt(stu.acts) + sqrt(events),
  data=lmdat
)

# Model statistics
summary(lmod)
```

Adjusted $r^2$ of .34 actually seems high to me for a first pass. Among the covariates, `deg.year` and the various engagement indicators are the most interesting. The factors `nice.title` and `nonprofit` are as expected. Before thinking about removing variables, check the diagnostic plots.

```{r, echo=F, message=F, warning=F, cache=F}
# Half-normal quantiles
QHalfNorm <- function(vec) {
  n <- length(vec)
  qnorm((n + 1:n) / (2 * n + 1))
}
# Create data
ggdat <- data.frame(id = lmdat$id, residual = lmod$residuals, fitted = lmod$fitted.values, actual = lmdat$student.gifts.lt, hatv = hatvalues(lmod), cook = cooks.distance(lmod), hnorm = QHalfNorm(cooks.distance(lmod)), rown = 1:nrow(lmdat))
# Plot fitted versus residual
ggplot(ggdat, aes(x=fitted, y=residual)) + geom_point(alpha=.25) + labs(title="Residuals versus fitted values") + geom_hline(yintercept=0, alpha=.25)
```

Nonlinearity is apparent as a result of the skewness in `student.gifts`, even after log transformation. There's a bit of unequal variance as well. Taking a more aggressive transformation might help but would make the model less interpretable.

```{r, echo=F, message=F, warning=F, cache=F}
# Calculate qqline based on quantiles of residuals
stat_qqline <- function(vec) {
  y <- quantile(vec, probs = c(.25, .75), na.rm = TRUE)
  x <- qnorm(c(.25, .75))
  a <- diff(y)/diff(x)
  b <- y[1] - a * x[1]
  return(
    list(geom_abline(slope = a, intercept = b, alpha = .25))
  )
}
# Plot observed versus fitted quantiles
ggplot(ggdat, aes(sample=residual)) + stat_qq(alpha=.25) + stat_qqline(ggdat$residual) + labs(title="Observed versus fitted quantiles")
```

As expected, giving data is thick-tailed -- at the extremes, there are both more high and low donors than expected.

```{r, echo=F, message=F, warning=F, cache=F}
# Plot Cook's distances
ggplot(ggdat, aes(x=hnorm, y=sort(cook))) + geom_point(alpha=.25) + labs(title="Cook's distance versus half-normal quantiles", x="Half-normal quantiles", y="Cook's distance")
# Residual versus leverage
ggplot(ggdat, aes(x=hatv, y=residual)) + geom_point(alpha=.25) + labs(title="Residuals vs. Leverage", x="Hat values")
```

Definitely a few extreme values there...

```{r, message=F, warning=F, cache=F}
ggdat %>% arrange(cook) %>% select(rown, cook, residual, hatv) %>% tail() %>% kable(digits=3)
ggdat %>% arrange(hatv) %>% select(rown, hatv, residual, cook) %>% tail() %>% kable(digits=3)
```

The five largest Cook's distances and leverages. Row 1730 is strange, with high leverage but no residual.

```{r, message=F, warning=F, cache=F}
summary(lmdat$deg.prg)
which(lmdat$deg.prg == "Other")
```

No wonder -- it's the only `deg.prg = Other` donor. This factor should be tweaked, for example by combining the `Other` and `Ph.D.` levels.

```{r, message=F, warning=F, cache=F}
levels(lmdat$deg.prg) <- c("Full-Time", '', "EMBA", "Other", "Part-Time", "Other")
lmdat <- lmdat %>% droplevels()
```

The `leaps` package can be used to check each subset of predictors to attempt to minimize the Bayesian information criterion.

```{r, message=F, warning=F, cache=F}
library(leaps)
lm.leaps <- regsubsets(
  student.gifts.lt ~
    # Low importance
     spouse + sqrt(events.stu) + lead.facil + nice.title + sqrt(scholarship) + stu.supp +
    # Use as-is
    deg.year.ctr + deg.prg + nice.title + fys.recent + nonprofit +
    # Sqrt transform
    sqrt(employ.yrs) + sqrt(fys.giving) + sqrt(af.gifts) + sqrt(known.to) + sqrt(committees) +
    sqrt(vols) + sqrt(speak) + sqrt(stu.acts) + sqrt(events),
  data=lmdat,
  nvmax=16)
```

```{r, echo=F, message=F, warning=F, cache=F}
# Best subsets
rsubs <- summary(lm.leaps)
# Plot BIC
ggdat <- data.frame(bic=rsubs$bic, p=(1:length(rsubs$bic)))
ggplot(ggdat, aes(x=p, y=bic)) + geom_point(alpha=.5) + geom_line(alpha=.25) + labs(title="BIC for different model sizes")
```

BIC is minimized by the following variables:

```{r, message=F, warning=F, cache=F}
# p minimizing BIC
(best <- which(rsubs$bic == min(rsubs$bic)))
# Best p variables (plus intercept) minimizing BIC
colnames(rsubs$which)[rsubs$which[best, ]]
```

Using just these in a new model yields the following:

```{r, message=F, warning=F, cache=F}
# Trimmed dataset
lmdat2 <- lmdat %>% mutate(emba = deg.prg=="EMBA") %>% select(id, nice.title, deg.year.ctr, emba, fys.recent, nonprofit, employ.yrs, known.to, committees, vols, speak, events, student.gifts.lt)
# Trimmed model
lmod2 <- lm(
  student.gifts.lt ~
    # Use as-is
    nice.title + deg.year.ctr + emba + fys.recent + nonprofit +
    # Sqrt transform
    sqrt(employ.yrs) + sqrt(known.to) + sqrt(committees) + sqrt(vols) + sqrt(speak) + sqrt(events),
  data=lmdat2
)
```

The residual and other diagnostic plots come out about the same.

```{r, echo=F, message=F, warning=F, cache=F}
# Residuals plot
# Create data
ggdat <- data.frame(id = lmdat2$id, residual = lmod2$residuals, fitted = lmod2$fitted.values, actual = lmdat2$student.gifts.lt, hatv = hatvalues(lmod2), cook = cooks.distance(lmod2), hnorm = QHalfNorm(cooks.distance(lmod2)), rown = 1:nrow(lmdat2))
# Plot fitted versus residual
ggplot(ggdat, aes(x=fitted, y=residual)) + geom_point(alpha=.25) + labs(title="Residuals versus fitted values") + geom_hline(yintercept=0, alpha=.25)
```

The model summary is interesting:

```{r, echo=F, message=F, warning=F, cache=F}
summary(lmod2)
```

On average, we'd guess that a donor to student causes has given about $2.27$ log dollars, or $10^2.27 = \$186$ without any other information. Younger alumni give less; all the other indicators increase giving on average.

From these variables, `nice.title`, `deg.year`, `nonprofit`, `known.to`, `committees`, and `speak` are particularly interesting as indicators because they both have relatively large coefficients and a lot of associated data.

# Prospect prioritization

From here, the simplest approach is to sort by predicted `student.gifts` within each gift capacity bin `gift.cap`.

```{r, echo=F, message=F, warning=F, cache=F}
# Prediction data
predsdat <- mdat %>% mutate(emba = deg.prg=="EMBA", deg.year.ctr = deg.year - min(lmdat$deg.year)) %>% filter(deg.prg != "") %>% droplevels()
# Predict on full dataset
preds <- predict(lmod2, newdata=predsdat)

# Plot expected versus actual, all data
ggdat <- data.frame(Predicted = 10^preds, Actual = predsdat$student.gifts, Capacity = predsdat$gift.cap) %>%
  mutate(Capacity = ifelse(Capacity == 0, "Unrated",
                    ifelse(Capacity <= 100000, " Up to $100k",
                    ifelse(Capacity > 100000, " Over $100k",
                           "Unrated"))) %>% as.factor())
ggdat %>% ggplot(aes(x=Predicted, y=Actual, color=Capacity)) + geom_point(alpha=.25) + gg.y.logdollar + gg.x.logdollar +
  labs(title="Predicted versus actual giving, all data")
```

When including non-donors, the predicted amounts are biased high, unsurprisingly. The final step is to join the predictions and unique identifier and export the data. For this first pass, it's helpful to have the data in Excel for others to explore. I'd been asked for a list of "200 to 1000 prospects" so people who have given substantially more or less than predicted are a reasonable place to start.

```{r, message=F, warning=F, cache=F}
# Save the id and prediction columns
out <- predsdat %>%
  select(id, actual = student.gifts.lt) %>%
  mutate(preds = preds, actual = ifelse(actual <= 0, 0, actual), residual = actual - preds)
```

Here's the distribution of differences:

```{r, echo=F, message=F, warning=F, cache=F}
# 250 largest and smallest residuals
q <- 250/length(out$res)
q <- list(quantile(out$residual, q),
          quantile(out$residual, 1-q))
# Set up the data
ggdat <- out %>% mutate(Capacity = predsdat$gift.cap) %>%
    mutate(Capacity = ifelse(Capacity == 0, "Unrated",
                    ifelse(Capacity <= 100000, " Up to $100k",
                    ifelse(Capacity > 100000, " Over $100k",
                           "Unrated"))) %>% as.factor())
# Check the distribution of lower and higher than expected
ggdat %>% ggplot(aes(x=residual)) + geom_histogram(bins=50, alpha=.5) + geom_hline(yintercept=0, color="white") +
  geom_vline(xintercept=q[[1]], alpha=.2, linetype="dashed") + geom_vline(xintercept=q[[2]], alpha=.2, linetype="dashed") +
  scale_y_sqrt(breaks=c(0, 1, 10, 100, 1000, seq(5000, 25000, by=5000)), minor_breaks=NULL) +
  labs(title = "Histogram of residuals of full dataset", y = "count (sqrt scale)")
# Boxplot of residuals
ggdat %>% ggplot(aes(x=residual, color=Capacity, fill=Capacity)) + geom_density(alpha=.2) +
  geom_vline(xintercept=q[[1]], alpha=.2, linetype="dashed") + geom_vline(xintercept=q[[2]], alpha=.2, linetype="dashed") +
  labs(title = "Density of residuals by capacity rating")
```

The vertical dashed lines indicate the cutoff for the 250 largest (gave more than expected) and 250 smallest (gave less than expected) residuals. Note that this is a mixture that is not even approximately centered around 0 -- this follows given that these residuals include out-of-sample individuals who have never given.

This does raise a question: can I get a better model if I account for non-student support lifetime giving? Here's the previous $r^2$:

```{r, echo=F, message=F, warning=F, cache=F}
summary(lmod2)$r.squared
```

And here's the new $r^2$ when including a term for `lt.giving` -- `student.gifts`

```{r, message=F, warning=F, cache=F}
# Add lifetime giving to lmdat2
lmdat2 <- lmdat2 %>% cbind(mdat %>% filter(student.gifts > 0) %>% select(lt.giving) %>%
  # Log10 transformation
  mutate(lt.giving.lt = log(lt.giving, base=10)))
# Use same model as lmod2, adding (lt.giving) as a predictor
lmod3 <- update(lmod2, . ~ . + I(lt.giving.lt - student.gifts.lt))
summary(lmod3)
```

Hmm, interesting. That is a substantial improvement, and doesn't actually affect the magnitude (or "significance") of the other coefficients much. Maybe it's nearly orthogonal to the others in this space, but it's problematic for prediction in that it can't be calculated without knowing the response variable.

```{r, message=F, warning=F, cache=F}
# Save as tab-delimited text
write.table(out, file="data\\predictions.csv", sep=",", row.names=F)
```

# Future ideas

* Prediction with cross-validation
* Model including non-donors
* [Tobit model](https://en.wikipedia.org/wiki/Tobit_model) for censored data

# Packages used
```{r}
session_info()
```